{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8412d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fc0c5",
   "metadata": {},
   "source": [
    "# Open file to extract list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5065f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['data/selections/colleges_and_universities.parquet']\n",
    "\n",
    "df_all = pd.read_parquet(files[0])\n",
    "\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "df_all = df_all.drop(df_all.index[df_all['TRANSACTION_DT'] == 'FL'])\n",
    "df_all = df_all.drop(df_all.index[df_all['TRANSACTION_DT'] == ''])\n",
    "\n",
    "OCCUPATION_dict = ['professor'] # ['professor', 'faculty', 'SCIENTIST', 'LECTURER']\n",
    "df_all = df_all[df_all['OCCUPATION'].str.contains(\"|\".join(OCCUPATION_dict), \n",
    "                                     case = False)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ea6cd",
   "metadata": {},
   "source": [
    "# Total number of unique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47e2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108267"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(df_all['NAME']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4baad",
   "metadata": {},
   "source": [
    "# Clean names\n",
    "Delete special symbols and various prefixes like Mr, Ms, PhD.\n",
    "Capitalize everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0de7bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_names = np.unique(df_all['NAME'])\n",
    "\n",
    "\n",
    "def clean(s):\n",
    "    s = unidecode(s)\n",
    "    s = s.upper()\n",
    "    s = s.replace('.','')\n",
    "    s = s.replace('`','')\n",
    "    s = s.replace('\"','')\n",
    "    s = s.replace(\"'\",'')\n",
    "    s = s.replace('*','')\n",
    "    s = s.replace('?','')\n",
    "    s = s.replace('/',' ')\n",
    "    s = s.replace('\\\\','')\n",
    "    s = s.split(' ')\n",
    "    if 'MS' in s:\n",
    "        s.remove('MS')\n",
    "    if 'MR' in s:\n",
    "        s.remove('MR')\n",
    "    if 'Mr' in s:\n",
    "        s.remove('Mr')\n",
    "    if 'MRS' in s:\n",
    "        s.remove('MRS')\n",
    "    if 'DR' in s:\n",
    "        s.remove('DR')\n",
    "    if 'PHD' in s:\n",
    "        s.remove('PHD')\n",
    "    if '' in s:\n",
    "        s.remove('')\n",
    "    s = ' '.join(s)\n",
    "    return(s)\n",
    "\n",
    "uni_names_clean = [clean(s) for s in uni_names]\n",
    "uni_names_clean = np.unique(uni_names_clean)\n",
    "uni_names_clean = uni_names_clean[uni_names_clean != '']\n",
    "\n",
    "def split_name(s):\n",
    "    s = s.split(',')\n",
    "    if len(s) > 1:\n",
    "        return s[0], s[1][1:]\n",
    "    else:\n",
    "        return '', ''\n",
    "    \n",
    "uni_names_clean = [split_name(s) for s in uni_names_clean]\n",
    "uni_names_clean = np.array(uni_names_clean)\n",
    "uni_names_clean = uni_names_clean[uni_names_clean[:,0]!='', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada63d7",
   "metadata": {},
   "source": [
    "# Numer of unique names after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73d519d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99887, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_names_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe4783",
   "metadata": {},
   "source": [
    "# Launching Chrome driver\n",
    "You have to donwload chromedriver.exe for your specific version of Chrome (many instructions online). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e457deff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-230-43186f31193e>:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/h-desktop/Downloads/chromedriver_win32/chromedriver.exe\", chrome_options=options)\n",
      "<ipython-input-230-43186f31193e>:6: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=\"C:/Users/h-desktop/Downloads/chromedriver_win32/chromedriver.exe\", chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "prefs = {'profile.default_content_settings.popups': 0, 'download.default_directory': 'd:\\\\'}\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "   #defined drive location\n",
    "    \n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/h-desktop/Downloads/chromedriver_win32/chromedriver.exe\", chrome_options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9304d",
   "metadata": {},
   "source": [
    "# Query for SCOPUS\n",
    "We run in a weird way through JS console. This is the only way I could make it work with VPN connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7751162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_data(lname, fname, driver, apikey):\n",
    "    result = driver.execute_async_script('''\n",
    "    var done = arguments[0];\n",
    "    let res;\n",
    "    fetch(\"https://api.elsevier.com/content/search/author?query=authlast(''' + lname + ''')%20and%20authfirst(''' + fname + ''')&apiKey=''' + apikey + '''\")\n",
    "         .then(resp=>resp.json())\n",
    "         .then(data=>{res = done(data)});\n",
    "    ''')\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1eb585",
   "metadata": {},
   "source": [
    "# Loop through the names and retrieve and save JSONs of search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b07ba348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 99887/99887 [1:07:41<00:00, 24.59it/s]\n"
     ]
    }
   ],
   "source": [
    "apikey = ['0fd07fa9c9c4d001ab07aeaab27c1f99', 'bdc326f7799d6022456f4549fbd9f0a6', '72f142ecd004ccb6fe07290c06979708', 'f1f024a0a23126c05ba6b6ef4fddb40e']\n",
    "# apikey = ['f9b80d824c5f0337ab5e1de00bcafa20', 'cb0ab27c914692912e9bba2245b01c3c', '7ea7ca00ebb9b00b1bfe3846fff8fcd2', '4bd1eda13c0c35fc025b38bbed3b2c99']\n",
    "apikey = ['a227ce8e04357c18f1ffb80270f07a02',\n",
    "'5a56c1429405660ade947deb1260a7c6',\n",
    "'8542d9eec4e3791cbbe8d5043215acb3',\n",
    "'0f5f55352206e75ff800ef4b47af19fd',\n",
    "'86ad2910d16cd1946ec1bc2296c68643',\n",
    "'ccf727f5c8354cfa92ee64395681efdb',\n",
    "'508410f93da3b8217a8857b97c285df6',\n",
    "'1dc4643cdc39ab0035c72939c04ae55a',\n",
    "'66b73b0f7c78970afa644d82bac01d78',\n",
    "'b5f3405db44bff95a068f5c00ef8a96a']\n",
    "\n",
    "for ii in tqdm(np.array(range(len(uni_names_clean)))[:]):\n",
    "    filename = \"C:\\\\data_academics\\\\\" + uni_names_clean[ii,0] + ', ' + uni_names_clean[ii,1] + '.json'\n",
    "    if not exists(filename):\n",
    "        x = get_auth_data(uni_names_clean[ii,0], uni_names_clean[ii,1], driver, apikey=apikey[ii % len(apikey)])\n",
    "        if 'error-response' not in x.keys():\n",
    "            if 'service-error' not in x.keys():\n",
    "                with open(filename, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(x, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(filename, 'r', encoding='utf-8') as f:\n",
    "#             x = json.load(f)\n",
    "#             if 'error-response' in x.keys():\n",
    "#                 x = get_auth_data(uni_names_clean[ii,0], uni_names_clean[ii,1], driver)\n",
    "#                 with open(filename, 'w', encoding='utf-8') as f:\n",
    "#                     json.dump(x, f, ensure_ascii=False, indent=4)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae19e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "868bb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 99887/99887 [10:15<00:00, 162.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ii in tqdm(range(len(uni_names_clean))):\n",
    "    filename = \"C:\\\\data_academics\\\\\" + uni_names_clean[ii,0] + ', ' + uni_names_clean[ii,1] + '.json'\n",
    "    if exists(filename):\n",
    "        delete = False\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            x = json.load(f)\n",
    "            if 'error-response' in x.keys():\n",
    "                delete = True\n",
    "            if 'service-error' in x.keys():\n",
    "                delete = True\n",
    "        if delete:\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e0c7b31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ZYSMAN', 'JOHN'], dtype='<U30')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_names_clean[ii,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6f12b398",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\data_academics\\\\BURKHART, HAROLD E.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-c64127ffaee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\data_academics\\\\BURKHART, HAROLD E.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\data_academics\\\\BURKHART, HAROLD E.json'"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\data_academics\\\\BURKHART, HAROLD E.json', 'r', encoding='utf-8') as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "33537ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7c2b0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('C:\\\\data_academics\\\\*.json')\n",
    "names = [f.split('\\\\')[-1][:-5] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "43eaa473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 83281/83281 [01:01<00:00, 1349.85it/s]\n"
     ]
    }
   ],
   "source": [
    "lookup_subj_area = []\n",
    "for n in tqdm(names):\n",
    "    filename = \"C:\\\\data_academics\\\\\" + n + '.json'\n",
    "    if exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            x = json.load(f)\n",
    "            if 'search-results' in x.keys():\n",
    "                if 'error' not in x['search-results']['entry'][0].keys():\n",
    "                    try:\n",
    "                        if len(x['search-results']['entry']) == 1:\n",
    "                            temp = x['search-results']['entry'][0]['subject-area']\n",
    "                            if type(temp) == dict:\n",
    "                                lookup_subj_area.append([n,  \\\n",
    "                                                     [[temp['@abbrev'], float(temp['@frequency'])]]])\n",
    "                            else:\n",
    "                                lookup_subj_area.append([n,  \\\n",
    "                                                     [[xx['@abbrev'], float(xx['@frequency'])] for xx in temp]])\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ac9d2ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@_fa': 'true',\n",
       "  'affiliation-current': {'affiliation-city': 'Berkeley',\n",
       "   'affiliation-country': 'United States',\n",
       "   'affiliation-id': '60025038',\n",
       "   'affiliation-name': 'University of California, Berkeley',\n",
       "   'affiliation-url': 'https://api.elsevier.com/content/affiliation/affiliation_id/60025038'},\n",
       "  'dc:identifier': 'AUTHOR_ID:6602689341',\n",
       "  'document-count': '44',\n",
       "  'eid': '9-s2.0-6602689341',\n",
       "  'link': [{'@_fa': 'true',\n",
       "    '@href': 'https://api.elsevier.com/content/author/author_id/6602689341',\n",
       "    '@ref': 'self'},\n",
       "   {'@_fa': 'true',\n",
       "    '@href': 'https://api.elsevier.com/content/search/author?query=au-id%286602689341%29',\n",
       "    '@ref': 'search'},\n",
       "   {'@_fa': 'true',\n",
       "    '@href': 'https://www.scopus.com/author/citedby.uri?partnerID=HzOxMe3b&citedAuthorId=6602689341&origin=inward',\n",
       "    '@ref': 'scopus-citedby'},\n",
       "   {'@_fa': 'true',\n",
       "    '@href': 'https://www.scopus.com/authid/detail.uri?partnerID=HzOxMe3b&authorId=6602689341&origin=inward',\n",
       "    '@ref': 'scopus-author'}],\n",
       "  'name-variant': [{'@_fa': 'true',\n",
       "    'given-name': 'J.',\n",
       "    'initials': 'J.',\n",
       "    'surname': 'Zysman'}],\n",
       "  'preferred-name': {'given-name': 'John',\n",
       "   'initials': 'J.',\n",
       "   'surname': 'Zysman'},\n",
       "  'prism:url': 'https://api.elsevier.com/content/author/author_id/6602689341',\n",
       "  'subject-area': [{'$': 'Social Sciences (all)',\n",
       "    '@abbrev': 'SOCI',\n",
       "    '@frequency': '28'},\n",
       "   {'$': 'Business, Management and Accounting (all)',\n",
       "    '@abbrev': 'BUSI',\n",
       "    '@frequency': '26'},\n",
       "   {'$': 'Economics, Econometrics and Finance (all)',\n",
       "    '@abbrev': 'ECON',\n",
       "    '@frequency': '11'}]}]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['search-results']['entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a96fec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lookup_subj_area)):\n",
    "    s = 0\n",
    "    for q in lookup_subj_area[i][1]:\n",
    "        s += q[1]\n",
    "    for q in lookup_subj_area[i][1]:\n",
    "        q[1] /= s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e95c5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5add7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_subj_area = np.array(lookup_subj_area, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e64f5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_subj_area_pd = pd.DataFrame(index=lookup_subj_area[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "69b2220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_areas = [np.array(i)[:, 0] for i in lookup_subj_area[:,  1]]\n",
    "all_areas = np.concatenate(all_areas)\n",
    "all_areas = np.unique(all_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "039478e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_areas:\n",
    "    lookup_subj_area_pd[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "aec15cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 27762/27762 [00:25<00:00, 1097.08it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(lookup_subj_area):\n",
    "    for q in row[1]:\n",
    "        lookup_subj_area_pd.loc[row[0]][q[0]] = q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c9e1383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRI</th>\n",
       "      <th>ARTS</th>\n",
       "      <th>BIOC</th>\n",
       "      <th>BUSI</th>\n",
       "      <th>CENG</th>\n",
       "      <th>CHEM</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DECI</th>\n",
       "      <th>DENT</th>\n",
       "      <th>EART</th>\n",
       "      <th>...</th>\n",
       "      <th>MATH</th>\n",
       "      <th>MEDI</th>\n",
       "      <th>MULT</th>\n",
       "      <th>NEUR</th>\n",
       "      <th>NURS</th>\n",
       "      <th>PHAR</th>\n",
       "      <th>PHYS</th>\n",
       "      <th>PSYC</th>\n",
       "      <th>SOCI</th>\n",
       "      <th>VETE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A, GILBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AADALEN, SHARON P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGAARD, TODD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAKER, JENNIFER</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AALGAARD, ROSS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYLAN, YVONNE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYLKIN, THOMAS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYLSTRA, UKO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYPHUR, MICHAEL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYSMAN, JOHN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27762 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AGRI  ARTS      BIOC      BUSI  CENG  CHEM      COMP  DECI  \\\n",
       "A, GILBERT          0.0   0.0  0.000000  0.000000   0.0   0.0  0.142857   0.0   \n",
       "AADALEN, SHARON P   0.0   0.0  0.000000  0.000000   0.0   0.0  0.000000   0.0   \n",
       "AAGAARD, TODD       0.0   0.0  0.000000  0.157895   0.0   0.0  0.000000   0.0   \n",
       "AAKER, JENNIFER     0.0   0.0  0.000000  0.524752   0.0   0.0  0.000000   0.0   \n",
       "AALGAARD, ROSS      0.0   0.0  0.000000  0.000000   0.0   0.0  0.000000   0.0   \n",
       "...                 ...   ...       ...       ...   ...   ...       ...   ...   \n",
       "ZYLAN, YVONNE       0.0   0.0  0.000000  0.000000   0.0   0.0  0.000000   0.0   \n",
       "ZYLKIN, THOMAS      0.0   0.0  0.000000  0.000000   0.0   0.0  0.000000   0.0   \n",
       "ZYLSTRA, UKO        0.0   0.0  0.333333  0.000000   0.0   0.0  0.000000   0.0   \n",
       "ZYPHUR, MICHAEL     0.0   0.0  0.000000  0.531532   0.0   0.0  0.000000   0.0   \n",
       "ZYSMAN, JOHN        0.0   0.0  0.000000  0.400000   0.0   0.0  0.000000   0.0   \n",
       "\n",
       "                   DENT  EART  ...      MATH      MEDI  MULT  NEUR      NURS  \\\n",
       "A, GILBERT          0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "AADALEN, SHARON P   0.0   0.0  ...  0.000000  0.166667   0.0   0.0  0.666667   \n",
       "AAGAARD, TODD       0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "AAKER, JENNIFER     0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "AALGAARD, ROSS      0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "...                 ...   ...  ...       ...       ...   ...   ...       ...   \n",
       "ZYLAN, YVONNE       0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "ZYLKIN, THOMAS      0.0   0.0  ...  0.230769  0.000000   0.0   0.0  0.000000   \n",
       "ZYLSTRA, UKO        0.0   0.0  ...  0.000000  0.166667   0.0   0.0  0.000000   \n",
       "ZYPHUR, MICHAEL     0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "ZYSMAN, JOHN        0.0   0.0  ...  0.000000  0.000000   0.0   0.0  0.000000   \n",
       "\n",
       "                   PHAR     PHYS      PSYC      SOCI  VETE  \n",
       "A, GILBERT          0.0  0.47619  0.000000  0.000000   0.0  \n",
       "AADALEN, SHARON P   0.0  0.00000  0.000000  0.000000   0.0  \n",
       "AAGAARD, TODD       0.0  0.00000  0.000000  0.736842   0.0  \n",
       "AAKER, JENNIFER     0.0  0.00000  0.237624  0.000000   0.0  \n",
       "AALGAARD, ROSS      0.0  0.00000  0.000000  1.000000   0.0  \n",
       "...                 ...      ...       ...       ...   ...  \n",
       "ZYLAN, YVONNE       0.0  0.00000  0.000000  1.000000   0.0  \n",
       "ZYLKIN, THOMAS      0.0  0.00000  0.000000  0.076923   0.0  \n",
       "ZYLSTRA, UKO        0.0  0.00000  0.000000  0.500000   0.0  \n",
       "ZYPHUR, MICHAEL     0.0  0.00000  0.324324  0.144144   0.0  \n",
       "ZYSMAN, JOHN        0.0  0.00000  0.000000  0.430769   0.0  \n",
       "\n",
       "[27762 rows x 27 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_subj_area_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d9abd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_subj_area_pd.to_parquet('lookup_subj_area_pd.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ed3f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('lookup_subj_area.npy', lookup_subj_area, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7431c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
